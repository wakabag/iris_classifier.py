{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNwYtpfVi2GfyLOsIUwp9LJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Import necessary libraries\n","import pandas as pd\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from sklearn.preprocessing import LabelEncoder\n","import numpy as np\n","\n","## --- 1. Data Loading and Inspection ---\n","print(\"## 1. Data Loading and Inspection\")\n","# Load the built-in Iris dataset\n","iris = load_iris()\n","\n","# Create a DataFrame for easier handling and inspection\n","df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n","df['species_name'] = iris.target_names[iris.target]\n","\n","print(\"First 5 rows of the dataset:\")\n","print(df.head())\n","print(\"\\nTarget Class Distribution:\")\n","print(df['species_name'].value_counts())\n","\n","## --- 2. Data Preprocessing (Handling missing values & Encoding) ---\n","print(\"\\n## 2. Data Preprocessing\")\n","\n","# a) Handle Missing Values (Check for simplicity, Iris is usually clean)\n","if df.isnull().sum().sum() > 0:\n","    print(\"WARNING: Missing values found. Handling them (e.g., imputation or removal)...\")\n","    # In a real-world scenario, you might impute: df.fillna(df.median(), inplace=True)\n","else:\n","    print(\"No missing values found in the Iris dataset.\")\n","\n","# b) Encode Labels (Target variable: species_name)\n","# Machine learning models require numerical labels.\n","le = LabelEncoder()\n","y_encoded = le.fit_transform(iris.target)\n","X = iris.data # Features\n","\n","# c) Split Data into Training and Testing sets\n","# Use a standard 70/30 split (70% for training, 30% for testing)\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded\n",")\n","\n","print(f\"X_train shape: {X_train.shape}, X_test shape: {X_test.shape}\")\n","\n","## --- 3. Model Training (Decision Tree Classifier) ---\n","print(\"\\n## 3. Model Training\")\n","\n","# Initialize the Decision Tree Classifier\n","dt_classifier = DecisionTreeClassifier(random_state=42)\n","\n","# Train the model using the training data\n","print(\"Training Decision Tree Classifier...\")\n","dt_classifier.fit(X_train, y_train)\n","print(\"Training complete.\")\n","\n","## --- 4. Model Evaluation ---\n","print(\"\\n## 4. Model Evaluation\")\n","\n","# Predict the species on the test set\n","y_pred = dt_classifier.predict(X_test)\n","\n","# Calculate Evaluation Metrics\n","accuracy = accuracy_score(y_test, y_pred)\n","# Use 'macro' for unweighted mean of metrics for each label (good for balanced datasets like Iris)\n","precision_macro = precision_score(y_test, y_pred, average='macro')\n","recall_macro = recall_score(y_test, y_pred, average='macro')\n","\n","# Display Results\n","print(f\"Decision Tree Classifier Results:\")\n","print(f\"  Accuracy: *{accuracy:.4f}* (Overall correct predictions)\")\n","print(f\"  Precision (Macro): *{precision_macro:.4f}* (Ability to not label as positive a sample that is negative)\")\n","print(f\"  Recall (Macro): *{recall_macro:.4f}* (Ability to find all the positive samples)\")\n","\n","# You can also get a full report for all classes\n","from sklearn.metrics import classification_report\n","print(\"\\nDetailed Classification Report:\")\n","print(classification_report(y_test, y_pred, target_names=iris.target_names))\n","\n","## --- 5. Example Prediction (Optional but useful for deliverable) ---\n","# Pick the first sample from the test set\n","sample_index = 0\n","sample_features = X_test[sample_index].reshape(1, -1)\n","sample_true_label = le.inverse_transform([y_test[sample_index]])[0]\n","\n","# Make a prediction\n","sample_prediction_encoded = dt_classifier.predict(sample_features)[0]\n","sample_prediction_name = le.inverse_transform([sample_prediction_encoded])[0]\n","\n","print(\"\\n--- Example Prediction ---\")\n","print(f\"Features: {sample_features[0]}\")\n","print(f\"True Species: *{sample_true_label}*\")\n","print(f\"Predicted Species: *{sample_prediction_name}*\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FWYEQYZEYUTS","executionInfo":{"status":"ok","timestamp":1762973026820,"user_tz":-180,"elapsed":199,"user":{"displayName":"iliyas Wakaba","userId":"04683041240243575298"}},"outputId":"07f74c6b-856c-4367-e5fc-031db11ba0c3"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["## 1. Data Loading and Inspection\n","First 5 rows of the dataset:\n","   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n","0                5.1               3.5                1.4               0.2   \n","1                4.9               3.0                1.4               0.2   \n","2                4.7               3.2                1.3               0.2   \n","3                4.6               3.1                1.5               0.2   \n","4                5.0               3.6                1.4               0.2   \n","\n","  species_name  \n","0       setosa  \n","1       setosa  \n","2       setosa  \n","3       setosa  \n","4       setosa  \n","\n","Target Class Distribution:\n","species_name\n","setosa        50\n","versicolor    50\n","virginica     50\n","Name: count, dtype: int64\n","\n","## 2. Data Preprocessing\n","No missing values found in the Iris dataset.\n","X_train shape: (105, 4), X_test shape: (45, 4)\n","\n","## 3. Model Training\n","Training Decision Tree Classifier...\n","Training complete.\n","\n","## 4. Model Evaluation\n","Decision Tree Classifier Results:\n","  Accuracy: *0.9333* (Overall correct predictions)\n","  Precision (Macro): *0.9444* (Ability to not label as positive a sample that is negative)\n","  Recall (Macro): *0.9333* (Ability to find all the positive samples)\n","\n","Detailed Classification Report:\n","              precision    recall  f1-score   support\n","\n","      setosa       1.00      1.00      1.00        15\n","  versicolor       1.00      0.80      0.89        15\n","   virginica       0.83      1.00      0.91        15\n","\n","    accuracy                           0.93        45\n","   macro avg       0.94      0.93      0.93        45\n","weighted avg       0.94      0.93      0.93        45\n","\n","\n","--- Example Prediction ---\n","Features: [7.3 2.9 6.3 1.8]\n","True Species: *2*\n","Predicted Species: *2*\n"]}]},{"cell_type":"code","metadata":{"id":"wI6zMle0XiY-"},"source":["# Necessary imports for data preparation and model\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.tree import DecisionTreeClassifier\n","\n","# --- Data Preparation (to define X_train, y_train) ---\n","# Load the built-in Iris dataset\n","iris = load_iris()\n","\n","# Encode Labels (Target variable: species_name)\n","le = LabelEncoder()\n","y_encoded = le.fit_transform(iris.target)\n","X = iris.data # Features\n","\n","# Split Data into Training and Testing sets\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded\n",")\n","\n","# --- Model Training ---\n","# Initialize the Decision Tree Classifier\n","dt_classifier = DecisionTreeClassifier(random_state=42)\n","\n","# Train the model using the training data\n","dt_classifier.fit(X_train, y_train)"],"execution_count":null,"outputs":[]}]}